{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing baseline neural networks defined in this paper [https://arxiv.org/pdf/1611.06455.pdf](https://arxiv.org/pdf/1611.06455.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from smokingml.modules import test, train, validate_on_holdouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIN_SIZE = 101\n",
    "\n",
    "class SmokingDataset(Dataset):\n",
    "    def __init__(self, dir):\n",
    "        self.dir = dir\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(os.listdir(self.dir))\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        if isinstance(key, slice):\n",
    "            stop, start, step = key.indices(len(self))\n",
    "\n",
    "            length = len(range(stop, start, step))\n",
    "            X = torch.zeros([length, 3*WIN_SIZE])\n",
    "            y = torch.zeros([length, 1])\n",
    "\n",
    "            for j,i in enumerate(range(stop, start, step)):\n",
    "                xi, yi = self[i]\n",
    "                X[j] = xi\n",
    "                y[j] = yi\n",
    "\n",
    "            return (X, y)\n",
    "\n",
    "        elif isinstance(key, int):\n",
    "            X, y = torch.load(os.path.join(self.dir, f'{key}.pt'))\n",
    "            return (X.flatten(), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = '../data/working-dataset-20Hz/'\n",
    "train_dataset = SmokingDataset(f'{dir}/4_all/train/')\n",
    "test_dataset = SmokingDataset(f'{dir}/4_all/test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:1 device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training\n",
    "device = \"cuda:1\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP\n",
    "\n",
    "Three hidden layer MLP, with 500 neurons each\n",
    "\n",
    "Dropout after each layer with probabilites:\n",
    "- 0.1 after input layer\n",
    "- 0.2 between hidden layers\n",
    "- 0.3 before output neuron\n",
    "\n",
    "\n",
    "one output neuron to predict smoking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model\n",
    "nhl = 500\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # First Hidden Layer\n",
    "        self.dropout1 = nn.Dropout(p=0.1)\n",
    "        self.h1 = nn.Linear(in_features=WIN_SIZE*3, out_features=nhl)\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        # Second Hidden Layer\n",
    "        self.dropout2 = nn.Dropout(p=0.2)\n",
    "        self.h2 = nn.Linear(in_features=nhl, out_features=nhl)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        # Third Hidden Layer\n",
    "        self.dropout3 = nn.Dropout(p=0.2)\n",
    "        self.h3 = nn.Linear(in_features=nhl, out_features=nhl)\n",
    "        self.relu3 = nn.ReLU()\n",
    "\n",
    "        # Output Layer\n",
    "        self.dropout4 = nn.Dropout(p=0.3)\n",
    "        self.h4 = nn.Linear(in_features=nhl, out_features=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # First Hidden Layer\n",
    "        x = self.dropout1(x)\n",
    "        x = self.h1(x)\n",
    "        x = self.relu1(x)\n",
    "\n",
    "        # Second Hidden Layer\n",
    "        x = self.dropout2(x)\n",
    "        x = self.h2(x)\n",
    "        x = self.relu2(x)\n",
    "\n",
    "        # Third Hidden Layer\n",
    "        x = self.dropout3(x)\n",
    "        x = self.h3(x)\n",
    "        x = self.relu3(x)\n",
    "\n",
    "        # Output Layer\n",
    "        x = self.dropout4(x)\n",
    "        logits = self.h4(x)\n",
    "\n",
    "        return logits\n",
    "\n",
    "model = MLP().to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adadelta(model.parameters(), lr=0.1, rho=0.95, eps=1e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 40\n",
    "batch_size = 64\n",
    "\n",
    "train(\n",
    "    train_dataset=train_dataset,\n",
    "    test_dataset=test_dataset,\n",
    "    model=model,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    test_batch_size=10000,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    date='',\n",
    "    device=device,\n",
    "    project='.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('./model/model-epoch-22.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on holdouts\n",
    "validate_on_holdouts(\n",
    "    model=model,\n",
    "    holdout_dir=f'{dir}/holdouts',\n",
    "    df_dir=f'{dir}/1_xyz',\n",
    "    raw_dir=f'{dir}/0_raw',\n",
    "    date='',\n",
    "    criterion=criterion,\n",
    "    batch_size=10000,\n",
    "    win_size=WIN_SIZE,\n",
    "    device=device,\n",
    "    project='.',\n",
    "    dm_factor=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on Holdouts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FCN\n",
    "Fully Convolutional Network\n",
    "All convolution with 1D kernels, no stride\n",
    "\n",
    "Three convolution blocks, all following by batch norm and relu:\n",
    "1. 128 kernels, kernel size 8\n",
    "2. 256 kernels, kernel size 5\n",
    "3. 128 kernels, kernel size 3\n",
    "\n",
    "Final global pooling layer before output neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape X to contain 3 channels (shape 3x101 instead of 303)\n",
    "\n",
    "WIN_SIZE = 101\n",
    "\n",
    "class SmokingDatasetCNN(Dataset):\n",
    "    def __init__(self, dir):\n",
    "        self.dir = dir\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(os.listdir(self.dir))\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        if isinstance(key, slice):\n",
    "            stop, start, step = key.indices(len(self))\n",
    "\n",
    "            length = len(range(stop, start, step))\n",
    "            X = torch.zeros([length, 3, WIN_SIZE])\n",
    "            y = torch.zeros([length, 1])\n",
    "\n",
    "            for j,i in enumerate(range(stop, start, step)):\n",
    "                xi, yi = self[i]\n",
    "                X[j] = xi.reshape(3, WIN_SIZE)\n",
    "                y[j] = yi\n",
    "\n",
    "            return (X, y)\n",
    "\n",
    "        elif isinstance(key, int):\n",
    "            X, y = torch.load(os.path.join(self.dir, f'{key}.pt'))\n",
    "            X = X.reshape([3, WIN_SIZE])\n",
    "            return (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SmokingDatasetCNN(f'{dir}/4_all/train')\n",
    "test_dataset = SmokingDatasetCNN(f'{dir}/4_all/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # First Convolution Block\n",
    "        self.conv1 = nn.Conv1d(in_channels=3, out_channels=128, kernel_size=8)\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=128)\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        # Second Convolution Block\n",
    "        self.conv2 = nn.Conv1d(in_channels=128, out_channels=256, kernel_size=5)\n",
    "        self.bn2 = nn.BatchNorm1d(num_features=256)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        # Third Convolution Block\n",
    "        self.conv3 = nn.Conv1d(in_channels=256, out_channels=128, kernel_size=3)\n",
    "        self.bn3 = nn.BatchNorm1d(num_features=128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "\n",
    "        # Global Average Pooling\n",
    "        self.gp = lambda x: torch.mean(x, dim=2)    # Take mean across each feature map (N, C, L) => (N,C)\n",
    "        \n",
    "        # Output Later\n",
    "        self.output = nn.Linear(in_features=128, out_features=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu3(x)\n",
    "\n",
    "        x = self.gp(x)\n",
    "        logits = self.output(x)\n",
    "\n",
    "        return logits\n",
    "\n",
    "model = FCN().to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m [\u001b[39msum\u001b[39m(p\u001b[39m.\u001b[39mnumel()) \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mparameters()]\n",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m [\u001b[39msum\u001b[39;49m(p\u001b[39m.\u001b[39;49mnumel()) \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mparameters()]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "[sum(p.numel()) for p in model.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "505025"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.numel() for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mStarting train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99: Testing: 100%|██████████| 100/100 [36:31<00:00, 21.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mFinished train. Elapsed time: 2191.554\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "batch_size = 64\n",
    "\n",
    "train(\n",
    "    train_dataset=train_dataset,\n",
    "    test_dataset=test_dataset,\n",
    "    model=model,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    test_batch_size=10000,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    date='',\n",
    "    device=device,\n",
    "    project='.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('./model/model-epoch-60.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mStarting validate_on_holdouts\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘./results/holdouts/60’: File exists\n",
      "mkdir: cannot create directory ‘./results/holdouts/57’: File exists\n",
      "mkdir: cannot create directory ‘./results/holdouts/53’: File exists\n",
      "mkdir: cannot create directory ‘./results/holdouts/8’: File exists\n",
      "mkdir: cannot create directory ‘./results/holdouts/31’: File exists\n",
      "mkdir: cannot create directory ‘./results/holdouts/27’: File exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌──────────┬──────────┬──────────┬──────────┬──────────┬─────────┬──────────┐\n",
      "│          │        8 │       27 │       31 │       53 │      57 │       60 │\n",
      "├──────────┼──────────┼──────────┼──────────┼──────────┼─────────┼──────────┤\n",
      "│ Accuracy │ 0.916761 │ 0.939541 │ 0.930349 │ 0.90411  │ 0.97551 │ 0.978006 │\n",
      "├──────────┼──────────┼──────────┼──────────┼──────────┼─────────┼──────────┤\n",
      "│ Loss     │ 2.15877  │ 0.714931 │ 1.62413  │ 0.707982 │ 1.17303 │ 0.360306 │\n",
      "└──────────┴──────────┴──────────┴──────────┴──────────┴─────────┴──────────┘\n",
      "\u001b[93mFinished validate_on_holdouts. Elapsed time: 6.879\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "validate_on_holdouts(\n",
    "    model=model,\n",
    "    holdout_dir=f'{dir}/holdouts',\n",
    "    df_dir=f'{dir}/1_xyz',\n",
    "    raw_dir=f'{dir}/0_raw',\n",
    "    date='',\n",
    "    criterion=criterion,\n",
    "    batch_size=10000,\n",
    "    win_size=WIN_SIZE,\n",
    "    device=device,\n",
    "    project='.',\n",
    "    dm_factor=5,\n",
    "    cnn=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet\n",
    "\n",
    "Adds shortcut connection in ecah residual block\n",
    "Three residual blocks. Each consist of three convolutional blocks \n",
    "- conv blocks are same as before of 64, 128, and 128 kernels each\n",
    "    - conv kernel size goes 8->5->3 for each residual block\n",
    "- final output of residual block is output of third convolutional block + input to residual block\n",
    "\n",
    "output of third residual block passed to a global pooling layer before a linear layer to a single output neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def conv_block(self, in_channels, out_channels, kernel_size, use_relu=True):\n",
    "        if use_relu:\n",
    "            return nn.Sequential(\n",
    "                nn.Conv1d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, padding='same'),\n",
    "                nn.BatchNorm1d(num_features=out_channels),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        else:\n",
    "            return nn.Sequential(\n",
    "                nn.Conv1d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, padding='same'),\n",
    "                nn.BatchNorm1d(num_features=out_channels)\n",
    "            )\n",
    "    \n",
    "    def inner_res_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            self.conv_block(in_channels=in_channels, out_channels=out_channels, kernel_size=8),\n",
    "            self.conv_block(in_channels=out_channels, out_channels=out_channels, kernel_size=5),\n",
    "            self.conv_block(in_channels=out_channels, out_channels=out_channels, kernel_size=3, use_relu=False)\n",
    "        )\n",
    "    \n",
    "    def shortcut(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv1d(in_channels=in_channels, out_channels=out_channels, kernel_size=1),\n",
    "            nn.BatchNorm1d(num_features=out_channels)\n",
    "        )\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # First ResNet Block components\n",
    "        self.shortcut1 = self.shortcut(in_channels=3, out_channels=64)\n",
    "        self.res1 = self.inner_res_block(in_channels=3, out_channels=64)\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        # Second Res Block components\n",
    "        self.shortcut2 = self.shortcut(in_channels=64, out_channels=128)\n",
    "        self.res2 = self.inner_res_block(in_channels=64, out_channels=128)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        # Third Res Block components\n",
    "        self.res3 = self.inner_res_block(in_channels=128, out_channels=128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "\n",
    "        # Global Pooling and output\n",
    "        self.gp = lambda x: torch.mean(x, dim=2)    # Take mean across each feature map (N, C, L) => (N,C)\n",
    "        self.output = nn.Linear(in_features=128, out_features=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # First Res Block\n",
    "        x_shortcut = self.shortcut1(x)\n",
    "        h = self.res1(x)\n",
    "        y = h + x_shortcut\n",
    "        y = self.relu1(y)\n",
    "\n",
    "        # Second Res Block\n",
    "        y_shortcut = self.shortcut2(y)\n",
    "        h = self.res2(y)\n",
    "        y = h + y_shortcut\n",
    "        y = self.relu2(y)\n",
    "\n",
    "        # Third Res Block\n",
    "        h = self.res3(y)\n",
    "        y = h + y\n",
    "        y = self.relu3(y)\n",
    "\n",
    "        # Global pooling and output\n",
    "        y = self.gp(y)\n",
    "        logits = self.output(y)\n",
    "        return logits\n",
    "\n",
    "model = ResNet().to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([64, 3, 1]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64, 3, 8]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64, 64, 5]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64, 64, 3]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([128, 64, 1]),\n",
       " torch.Size([128]),\n",
       " torch.Size([128]),\n",
       " torch.Size([128]),\n",
       " torch.Size([128, 64, 8]),\n",
       " torch.Size([128]),\n",
       " torch.Size([128]),\n",
       " torch.Size([128]),\n",
       " torch.Size([128, 128, 5]),\n",
       " torch.Size([128]),\n",
       " torch.Size([128]),\n",
       " torch.Size([128]),\n",
       " torch.Size([128, 128, 3]),\n",
       " torch.Size([128]),\n",
       " torch.Size([128]),\n",
       " torch.Size([128]),\n",
       " torch.Size([128, 128, 8]),\n",
       " torch.Size([128]),\n",
       " torch.Size([128]),\n",
       " torch.Size([128]),\n",
       " torch.Size([128, 128, 5]),\n",
       " torch.Size([128]),\n",
       " torch.Size([128]),\n",
       " torch.Size([128]),\n",
       " torch.Size([128, 128, 3]),\n",
       " torch.Size([128]),\n",
       " torch.Size([128]),\n",
       " torch.Size([128]),\n",
       " torch.Size([1, 128]),\n",
       " torch.Size([1])]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p.shape for p in model.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mStarting train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: Training:   0%|          | 0/40 [00:00<?, ?it/s]/home/musa/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:309: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at ../aten/src/ATen/native/Convolution.cpp:1003.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "Epoch 39: Testing: 100%|██████████| 40/40 [14:32<00:00, 21.81s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mFinished train. Elapsed time: 872.438\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 40\n",
    "batch_size = 64\n",
    "\n",
    "train(\n",
    "    train_dataset=train_dataset,\n",
    "    test_dataset=test_dataset,\n",
    "    model=model,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    test_batch_size=10000,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    date='',\n",
    "    device=device,\n",
    "    project='.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mStarting validate_on_holdouts\u001b[0m\n",
      "┌──────────┬──────────┬──────────┬──────────┬──────────┬──────────┬──────────┐\n",
      "│          │        8 │       27 │       31 │       53 │       57 │       60 │\n",
      "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Accuracy │ 0.923756 │ 0.945088 │ 0.93476  │ 0.937832 │ 0.97932  │ 0.97638  │\n",
      "├──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Loss     │ 2.94085  │ 0.527736 │ 0.939097 │ 0.487714 │ 0.598341 │ 0.216511 │\n",
      "└──────────┴──────────┴──────────┴──────────┴──────────┴──────────┴──────────┘\n",
      "\u001b[93mFinished validate_on_holdouts. Elapsed time: 6.998\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "validate_on_holdouts(\n",
    "    model=model,\n",
    "    holdout_dir=f'{dir}/holdouts',\n",
    "    df_dir=f'{dir}/1_xyz',\n",
    "    raw_dir=f'{dir}/0_raw',\n",
    "    date='',\n",
    "    criterion=criterion,\n",
    "    batch_size=10000,\n",
    "    win_size=WIN_SIZE,\n",
    "    device=device,\n",
    "    project='.',\n",
    "    dm_factor=5,\n",
    "    cnn=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
