{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get raw, windowed data\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "if not os.path.exists('./inet_data/raw/smoking_input.csv') or not os.path.exists('./inet_data/raw/smoking_targets.csv'):\n",
    "    os.system('mkdir -p inet_data/raw')\n",
    "    urllib.request.urlretrieve(\"http://ifestos.cse.sc.edu/datasets/smoking_data.tar.gz\", \"inet_data/smoking_data.tar.gz\")\n",
    "\n",
    "    os.system('tar -xzvf inet_data/smoking_data.tar.gz -C inet_data/raw/ --strip-components=1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "X = pd.read_csv('inet_data/raw/smoking_input.csv', header=None)\n",
    "y = pd.read_csv('inet_data/raw/smoking_targets.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cpu or gpu device for training\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatting & Preprocessing\n",
    "\n",
    "y.columns = [\"label\"]\n",
    "\n",
    "# Fill NaNs\n",
    "X = X.fillna(method='bfill')\n",
    "\n",
    "# Put in torch tensors\n",
    "X_pt = torch.from_numpy(X.to_numpy()).float().to(device)\n",
    "y_pt = torch.from_numpy(y.to_numpy()).float().to(device)\n",
    "\n",
    "# train-test split\n",
    "\n",
    "\n",
    "(X_train, X_test, y_train, y_test) = train_test_split(X_pt, y_pt, test_size=0.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Model\n",
    "- input layer 300 -> 10\n",
    "- activation function ReLU\n",
    "- hidden layer 10 -> 1\n",
    "- output function Tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(300, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(5, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epochs, batch_size, loss_fn, optimizer, X_train, X_test, y_train, y_test):\n",
    "    losses = np.zeros(epochs)\n",
    "    test_losses = np.zeros(epochs)\n",
    "\n",
    "    model.train()\n",
    "    for i in range(epochs):\n",
    "        for j in range(0, len(X_train), batch_size):\n",
    "            end = j+batch_size if j+batch_size < len(X_train) else len(X_train)\n",
    "\n",
    "            # Forward pass\n",
    "            logits = model(X_train[j:end])\n",
    "            loss = loss_fn(logits, y_train[j:end])\n",
    "\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            losses[i] += loss\n",
    "\n",
    "        losses[i] /= batch_size # get mean loss of all batches this epoch\n",
    "\n",
    "        test_logits = model(X_test)\n",
    "        test_loss = loss_fn(test_logits, y_test)\n",
    "        test_losses[i] = test_loss\n",
    "\n",
    "        if i%10 == 0:\n",
    "            print(f\"Epoch {i}: \", end='')\n",
    "            print(f'\\tLoss={loss.item()}', end='')\n",
    "            print(f'\\tTest Loss={test_loss.item()}')\n",
    "\n",
    "    return (losses, test_losses)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(X_test)\n",
    "\n",
    "    loss = loss_fn(logits, y_test)\n",
    "\n",
    "    pred = torch.round(nn.Sigmoid()(logits))\n",
    "    accuracy = (sum(y_test == pred) / len(y_test)).item()\n",
    "\n",
    "print(f'Test Loss: {loss:.4}')\n",
    "print(f'Accuracy: {100*accuracy:.4}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "\n",
    "os.system('mkdir model')\n",
    "torch.save(model.state_dict(), 'model/model.pt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on Continous Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cpu or gpu device for training\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_index = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "\n",
    "raw = pd.read_csv(f'data/{file_index}/raw_data.csv', header=None)\n",
    "\n",
    "# Window Data\n",
    "df = raw[[2,3,4]]\n",
    "\n",
    "X = np.empty((len(df)-99, 300), dtype=float)\n",
    "for i in range(len(df)-99):\n",
    "    X[i] = df[i:i+100].to_numpy().T.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels\n",
    "annot = {}\n",
    "y = np.zeros((len(X)))\n",
    "\n",
    "\n",
    "with open(f'data/{file_index}/16_data.json') as f:\n",
    "    annot = json.load(f)\n",
    "\n",
    "for i in range(annot['start'], annot['end']):\n",
    "    for puff in annot['puffs']:\n",
    "        if i >= puff['start'] and i <= puff['end'] - 99:\n",
    "            y[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize true labels\n",
    "\n",
    "df['labels'] = np.pad(y*10, (0,99), mode='constant', constant_values=5)\n",
    "\n",
    "fig = px.line(data_frame=df.loc[::10,[2, \"labels\"]])\n",
    "fig.show(renderer='browser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict labels\n",
    "\n",
    "X_pt = torch.from_numpy(X).float().to(device)\n",
    "y_pt = torch.from_numpy(y).reshape(-1,1).float().to(device)\n",
    "\n",
    "model = MLP().to(device)\n",
    "model.load_state_dict(torch.load('model/model.pt'))\n",
    "model.eval()\n",
    "\n",
    "step = 10000    # for memory\n",
    "preds = []\n",
    "correct = 0\n",
    "for i in range(0, len(X_pt), step):\n",
    "    end = i+step if i+step < len(X_pt) else len(X_pt)\n",
    "    with torch.no_grad():\n",
    "        logits = model(X_pt[i:end])\n",
    "        pred = torch.round(nn.Sigmoid()(logits))\n",
    "        correct += sum(y_pt[i:end] == pred)\n",
    "        preds += pred.flatten().tolist()\n",
    "\n",
    "preds = np.array(preds)\n",
    "accuracy = (correct / len(y_pt)).item()\n",
    "print(f'Accuracy: {100*accuracy:.4}%')  # falsely high bc of all the true negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy based on just the smoking session windows\n",
    "X_smoking = X[annot['start']:annot['end']]\n",
    "preds_smoking = preds[annot['start']:annot['end']]\n",
    "\n",
    "acc_smoking = sum(preds_smoking == y[annot['start']:annot['end']]) / len(preds_smoking)\n",
    "\n",
    "print(f'Accuracy in Smoking Session: {100*acc_smoking:.4}%')  # still high bc of the true negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy by true positives\n",
    "\n",
    "tps = 0\n",
    "for i in range(len(y)):\n",
    "    tps += (y[i] and preds[i])  # add one if both are 1\n",
    "\n",
    "# acc_tp = len(np.where(preds==1)[0]) / len(np.where(y==1)[0])\n",
    "acc_tp = tps / len(np.where(y==1)[0])\n",
    "print(f'Percent of positives predicted: {100*acc_tp:.4}%')  # oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions\n",
    "\n",
    "df['preds'] = np.pad(preds*10, (0, 99), mode='constant', constant_values=0)\n",
    "\n",
    "figure = px.line(df.loc[::10, [2, 'labels', 'preds']])\n",
    "figure.show(renderer='browser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "\n",
    "model = MLP().to(device)\n",
    "\n",
    "(X_train, X_test, y_train, y_test) = train_test_split(X_pt[annot['start']:annot['end']], y_pt[annot['start']:annot['end']], test_size=0.25, stratify=y_pt[annot['start']:annot['end']].to('cpu'))\n",
    "\n",
    "# Loss function and optimizer\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 128\n",
    "\n",
    "(losses, test_losses) = train(model, epochs, batch_size, loss_fn, optimizer, X_train, X_test, y_train, y_test)\n",
    "\n",
    "figure = px.line(pd.DataFrame({\"loss\": losses, \"validation loss\":test_losses}))\n",
    "figure.show(renderer='browser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model(X_test)\n",
    "pred = nn.Sigmoid()(logits).argmax(axis=1)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test.detach().to('cpu'), pred.detach().to('cpu'), normalize=\"true\")\n",
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.where(y_train.to('cpu')==1)[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
