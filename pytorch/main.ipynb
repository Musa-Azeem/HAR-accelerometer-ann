{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get raw, windowed data\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "if not os.path.exists('./data/raw/smoking_input.csv') or not os.path.exists('./data/raw/smoking_targets.csv'):\n",
    "    os.system('mkdir -p data/raw')\n",
    "    urllib.request.urlretrieve(\"http://ifestos.cse.sc.edu/datasets/smoking_data.tar.gz\", \"data/smoking_data.tar.gz\")\n",
    "\n",
    "    os.system('tar -xzvf data/smoking_data.tar.gz -C data/raw/ --strip-components=1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "X = pd.read_csv('data/raw/smoking_input.csv', header=None)\n",
    "y = pd.read_csv('data/raw/smoking_targets.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Formatting & Preprocessing\n",
    "\n",
    "# Get cpu or gpu device for training\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "y.columns = [\"label\"]\n",
    "\n",
    "# Fill NaNs\n",
    "X = X.fillna(method='bfill')\n",
    "\n",
    "# Put in torch tensors\n",
    "X_pt = torch.from_numpy(X.to_numpy()).float().to(device)\n",
    "y_pt = torch.from_numpy(y.to_numpy()).float().to(device)\n",
    "\n",
    "# train-test split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "(X_train, X_test, y_train, y_test) = train_test_split(X_pt, y_pt, test_size=0.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Model\n",
    "- input layer 300 -> 10\n",
    "- activation function ReLU\n",
    "- hidden layer 10 -> 1\n",
    "- output function Tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(300, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits  \n",
    "\n",
    "model = MLP().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: \tLoss=0.7529674768447876\n",
      "Epoch 100: \tLoss=0.03200244903564453\n",
      "Epoch 200: \tLoss=0.016902804374694824\n",
      "Epoch 300: \tLoss=0.010966378264129162\n",
      "Epoch 400: \tLoss=0.006567590404301882\n",
      "Epoch 500: \tLoss=0.00480006355792284\n",
      "Epoch 600: \tLoss=0.0037112447898834944\n",
      "Epoch 700: \tLoss=0.0028870324604213238\n",
      "Epoch 800: \tLoss=0.0023192083463072777\n",
      "Epoch 900: \tLoss=0.0019045922672376037\n",
      "Epoch 1000: \tLoss=0.0015605189837515354\n",
      "Epoch 1100: \tLoss=0.001278255949728191\n",
      "Epoch 1200: \tLoss=0.0010367868235334754\n",
      "Epoch 1300: \tLoss=0.0008328840485773981\n",
      "Epoch 1400: \tLoss=0.000656703719869256\n",
      "Epoch 1500: \tLoss=0.0005191547679714859\n",
      "Epoch 1600: \tLoss=0.0004152397159487009\n",
      "Epoch 1700: \tLoss=0.0003379601112101227\n",
      "Epoch 1800: \tLoss=0.00027638388564810157\n",
      "Epoch 1900: \tLoss=0.00022878227173350751\n",
      "Epoch 2000: \tLoss=0.0001926984405145049\n",
      "Epoch 2100: \tLoss=0.000163731470820494\n",
      "Epoch 2200: \tLoss=0.00014037500659469515\n",
      "Epoch 2300: \tLoss=0.00012152841372881085\n",
      "Epoch 2400: \tLoss=0.00010690922499634326\n"
     ]
    }
   ],
   "source": [
    "# Loss function and optimizer\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "model.train()\n",
    "\n",
    "epochs = 2500\n",
    "for i in range(epochs):\n",
    "    # Predict and calulate loss on X train\n",
    "    logits = model(X_train)\n",
    "    loss = loss_fn(logits, y_train)\n",
    "\n",
    "    # Backpropagation\n",
    "\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i%100 == 0:\n",
    "        print(f\"Epoch {i}: \", end='')\n",
    "        print(f'\\tLoss={loss.item()}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.004102\n",
      "Accuracy: 99.93%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(X_test)\n",
    "\n",
    "loss = loss_fn(logits, y_test)\n",
    "\n",
    "pred = torch.round(nn.Sigmoid()(logits))\n",
    "accuracy = (sum(y_test == pred) / len(y_test)).item()\n",
    "\n",
    "print(f'Test Loss: {loss:.4}')\n",
    "print(f'Accuracy: {100*accuracy:.4}%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on Continous Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_index = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "\n",
    "df = pd.read_csv(f'data/{file_index}/raw_data.csv', header=None)\n",
    "\n",
    "# Window Data\n",
    "X_raw = df[[2,3,4]]\n",
    "\n",
    "X = np.empty((len(X_raw)-99, 300), dtype=float)\n",
    "for i in range(len(X_raw)-99):\n",
    "    X[i] = X_raw[i:i+100].to_numpy().T.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels\n",
    "import json\n",
    "\n",
    "annot = {}\n",
    "y = np.zeros((len(X)))\n",
    "\n",
    "\n",
    "with open(f'data/{file_index}/16_data.json') as f:\n",
    "    annot = json.load(f)\n",
    "\n",
    "for i in range(annot['start'], annot['end']):\n",
    "    for puff in annot['puffs']:\n",
    "        if i >= puff['start'] and i <= puff['end'] - 99:\n",
    "            y[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.823242</td>\n",
       "      <td>0.227417</td>\n",
       "      <td>10.031250</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.809082</td>\n",
       "      <td>0.318359</td>\n",
       "      <td>10.125000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.749023</td>\n",
       "      <td>0.406982</td>\n",
       "      <td>10.031250</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.780273</td>\n",
       "      <td>0.437988</td>\n",
       "      <td>10.054688</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.878418</td>\n",
       "      <td>0.442871</td>\n",
       "      <td>10.179688</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142495</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142496</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142497</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142498</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142499</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>285000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               2         3          4    0\n",
       "0       0.823242  0.227417  10.031250  NaN\n",
       "1       0.809082  0.318359  10.125000  NaN\n",
       "2       0.749023  0.406982  10.031250  NaN\n",
       "3       0.780273  0.437988  10.054688  NaN\n",
       "4       0.878418  0.442871  10.179688  NaN\n",
       "...          ...       ...        ...  ...\n",
       "142495       NaN       NaN        NaN  0.0\n",
       "142496       NaN       NaN        NaN  0.0\n",
       "142497       NaN       NaN        NaN  0.0\n",
       "142498       NaN       NaN        NaN  0.0\n",
       "142499       NaN       NaN        NaN  0.0\n",
       "\n",
       "[285000 rows x 4 columns]"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "\n",
    "fig = px.line(data_frame=df[[2,3,4]])\n",
    "# fig.show(renderer='browser')\n",
    "y_graph = np.pad(y, (0,99), mode='edge')\n",
    "pd.concat([X_raw, pd.DataFrame(y_graph)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
